res0=mmzero[2]-mmzero[1]+1
res1=mmone[2]-mmone[1]+1
# dimension zero
pi0group1 = pi0group2 = pi0group3 = pi0group4 = array(
dim=c(mmzero[2]-mmzero[1]+1,mmzero[2]-mmzero[1]+1,50))
# dimension one
pi1group1 = pi1group2 = pi1group3 = pi1group4 = array(
dim=c(mmone[2]-mmone[1]+1,mmone[2]-mmone[1]+1,50) )
for (ii in 1:50){
pi0group1[,,ii] = pilist0[[ii]] # group 1
pi0group2[,,ii] = pilist0[[ii+50]] # group 2
pi0group3[,,ii] = pilist0[[ii+100]] # group 3
pi0group4[,,ii] = pilist0[[ii+150]] # group 4
pi1group1[,,ii] = pilist1[[ii]]
pi1group2[,,ii] = pilist1[[ii+50]]
pi1group3[,,ii] = pilist1[[ii+100]]
pi1group4[,,ii] = pilist1[[ii+150]]
}
# scenario 1
## p values, unfiltered
sc1_arctan_dim0=ttestpi(pi0group1,pi0group2,res0) # dimension zero
sc1_arctan_dim1=ttestpi(pi1group1,pi1group2,res1) # dimension one
## p values, filtered and adjusted
pval10=testfun(sc1_arctan_dim0,mmzero,mmzero+abs(min(mmzero)),cc)
pval11=testfun(sc1_arctan_dim1,mmone,mmone+abs(min(mmone)),cc)
# scenario 2
## p values, unfiltered
sc2_arctan_dim0=ttestpi(pi0group1,pi0group3,res0) # dimension zero
sc2_arctan_dim1=ttestpi(pi1group1,pi1group3,res1) # dimension one
## p values, filtered and adjusted
pval20=testfun(sc2_arctan_dim0,mmzero,mmzero+abs(min(mmzero)),cc)
pval21=testfun(sc2_arctan_dim1,mmone,mmone+abs(min(mmone)),cc)
# scenario 3
## p values, unfiltered
sc3_arctan_dim0=ttestpi(pi0group1,pi0group4,res0) # dimension zero
sc3_arctan_dim1=ttestpi(pi1group1,pi1group4,res1) # dimension one
## p values, filtered and adjusted
pval30=testfun(sc3_arctan_dim0,mmzero,mmzero+abs(min(mmzero)),cc)
pval31=testfun(sc3_arctan_dim1,mmone,mmone+abs(min(mmone)),cc)
# scenario 4
## p values, unfiltered
sc4_arctan_dim0=anovapi(pi0group1,pi0group3,pi0group4,res0) # dimension zero
sc4_arctan_dim1=anovapi(pi1group1,pi1group3,pi1group4,res1) # dimension one
## p values, filtered and adjusted
pval40=testfun(sc4_arctan_dim0,mmzero,mmzero+abs(min(mmzero)),cc)
pval41=testfun(sc4_arctan_dim1,mmone,mmone+abs(min(mmone)),cc)
return(c(pval10,pval11,pval20,pval21,pval30,pval31,pval40,pval41))
}
###############################################################
# Functions for Robins and Turner
###############################################################
# test Robins and Turner
rttest=function(pd1,pd2,nset) {
jointlabel=t(combn(1:nset,2))
perf=rep(NA,nrow(jointlabel))
for (ii in 1:nrow(jointlabel)) {
perf[ii]=TDA::wasserstein(pdlist1[[jointlabel[ii,1]]],pdlist1[[jointlabel[ii,2]]])+
TDA::wasserstein(pdlist2[[jointlabel[ii,1]]],pdlist2[[jointlabel[ii,2]]])
}
return(mean(perf))
}
# test Robins and Turner
parrttest=function(kk,pdlist,rr,nset,ntotalset) {
pdlist1 = list()
pdlist2 = list()
shufflelabel=sample(1:(2*nset),(2*nset))
for (ss in 1:nset){
pdlist1[[ss]]=pdlist[[ (rr-1)*nset + shufflelabel[ss] ]]
pdlist2[[ss]]=pdlist[[ (rr-1)*nset + ntotalset + shufflelabel[ss] ]]
}
jointlabel=t(combn(1:nset,2))
perf=rep(NA,nrow(jointlabel))
for( ii in 1:nrow(jointlabel)) {
perf[ii]=TDA::wasserstein(pdlist1[[jointlabel[ii,1]]],pdlist1[[jointlabel[ii,2]]])+
TDA::wasserstein(pdlist2[[jointlabel[ii,1]]],pdlist2[[jointlabel[ii,2]]])
}
return(mean(perf))
}
###############################################################
# Functions for persistence landscape
# Modified from https://people.clas.ufl.edu/peterbubenik/files/intro_tda.txt
###############################################################
landscape.matrix.from.list <- function(PL.list){
n <- length(PL.list)
m <- ncol(PL.list[[1]])
max.depth <- integer(n)
for (i in 1:n)
max.depth[i] <- nrow(PL.list[[i]])
K <- max(max.depth)
PL.matrix <- matrix(0, nrow = n, ncol = m*K)
for (i in 1:n)
for (j in 1:max.depth[i])
PL.matrix[i,(1+(j-1)*m):(j*m)] <- PL.list[[i]][j,]
return(PL.matrix)
}
testfun = function(ii,M,n,k){
euclidean.distance <- function(a, b) sqrt(sum((a - b)^2))
permutation <- sample(1:n)
t <- euclidean.distance(colMeans(M[permutation[1:k],]),colMeans(M[permutation[(k+1):n],]))
return(t)
}
permutation.test <- function(M1 ,M2, num.repeats = 5000, cl){
euclidean.distance <- function(a, b) sqrt(sum((a - b)^2))
# append zeros if necessary so that the matrices have the same number of columns
num.columns <- max(ncol(M1),ncol(M2))
M1 <- cbind(M1, matrix(0,nrow=nrow(M1),ncol=num.columns-ncol(M1)))
M2 <- cbind(M2, matrix(0,nrow=nrow(M2),ncol=num.columns-ncol(M2)))
t.obs <- euclidean.distance(colMeans(M1),colMeans(M2))
k <- dim(M1)[1]
M <- rbind(M1,M2)
n <- dim(M)[1]
tvec=parApply(cl,as.matrix(1:num.repeats),1,testfun,M,n,k)
return(sum(tvec<t.obs)/num.repeats)
}
###############################################################
# Functions for DTW
###############################################################
# baseline of the permutation test
baseline=function(ts1,ts2,nts) {
jointlabel=t(combn(1:nts,2))
perf=rep(NA,nrow(jointlabel))
for (ii in 1:nrow(jointlabel)) {
perf[ii]=dtw::dtw(ts1[jointlabel[ii,1],],ts1[jointlabel[ii,2],])$distance+
dtw::dtw(ts2[jointlabel[ii,1],],ts1[jointlabel[ii,2],])$distance
}
return(mean(perf))
}
# permutation test
permtest=function(kk,tsdata,rr,nts,nset,ntotalset) {
shufflelabel=sample(1:(2*nset),(2*nset))
ts1 = tsdata[shufflelabel[1:nset],]
ts2 = tsdata[shufflelabel[(nset+1):(2*nset)],]
jointlabel=t(combn(1:nts,2))
perf=rep(NA,nrow(jointlabel))
for( ii in 1:nrow(jointlabel)) {
perf[ii]=dtw::dtw(ts1[jointlabel[ii,1],],ts1[jointlabel[ii,2],])$distance+
dtw::dtw(ts2[jointlabel[ii,1],],ts1[jointlabel[ii,2],])$distance
}
return(mean(perf))
}
#########################################################
# between aperiodic and stable regimes
#########################################################
nrep=100 # number of sets
nset=20 # number of data in one set
ntotalset=4000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # power
#########################################################
# between aperiodic regimes
#########################################################
nrep=100
nset=20
ntotalset=2000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # false positive rate
#########################################################
# between stable regimes
#########################################################
nrep=100
nset=20
ntotalset=2000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss+4000]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+4000+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # false positive rate
#########################################################
# between aperiodic and stable regimes
#########################################################
nrep=100 # number of sets
nset=20 # number of data in one set
ntotalset=4000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # power
pvals
View(permutation.test)
source("functions.R")
# import persistence diagrams
load("./data_persistence_diagram.Rdata")
set.seed(75)
cl = makeCluster(detectCores()-1)
# create persistence landscape
PL.list=list()
for (ii in 1:length(pdlist)){
pd=pdlist[[ii]]
PL.list[[ii]]=t(landscape(pd,dimension=1,KK=1:50,tseq=seq(0,100,length=500)))
}
np=500 # number of permutation
#########################################################
# between aperiodic and stable regimes
#########################################################
nrep=100 # number of sets
nset=20 # number of data in one set
ntotalset=4000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # power
#########################################################
# between aperiodic regimes
#########################################################
nrep=100
nset=20
ntotalset=2000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # false positive rate
#########################################################
# between stable regimes
#########################################################
nrep=100
nset=20
ntotalset=2000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss+4000]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+4000+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # false positive rate
stopCluster(cl)
landscape.matrix.from.list <- function(PL.list){
n <- length(PL.list)
m <- ncol(PL.list[[1]])
max.depth <- integer(n)
for (i in 1:n)
max.depth[i] <- nrow(PL.list[[i]])
K <- max(max.depth)
PL.matrix <- matrix(0, nrow = n, ncol = m*K)
for (i in 1:n)
for (j in 1:max.depth[i])
PL.matrix[i,(1+(j-1)*m):(j*m)] <- PL.list[[i]][j,]
return(PL.matrix)
}
testfun = function(ii,M,n,k){
euclidean.distance <- function(a, b) sqrt(sum((a - b)^2))
permutation <- sample(1:n)
t <- euclidean.distance(colMeans(M[permutation[1:k],]),colMeans(M[permutation[(k+1):n],]))
return(t)
}
permutation.test <- function(M1 ,M2, num.repeats = 5000, cl){
euclidean.distance <- function(a, b) sqrt(sum((a - b)^2))
# append zeros if necessary so that the matrices have the same number of columns
num.columns <- max(ncol(M1),ncol(M2))
M1 <- cbind(M1, matrix(0,nrow=nrow(M1),ncol=num.columns-ncol(M1)))
M2 <- cbind(M2, matrix(0,nrow=nrow(M2),ncol=num.columns-ncol(M2)))
t.obs <- euclidean.distance(colMeans(M1),colMeans(M2))
k <- dim(M1)[1]
M <- rbind(M1,M2)
n <- dim(M)[1]
tvec=parApply(cl,as.matrix(1:num.repeats),1,testfun,M,n,k)
return(sum(tvec>=t.obs)/num.repeats)
}
set.seed(75)
nrep=100 # number of sets
nset=20 # number of data in one set
ntotalset=4000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # power
cl = makeCluster(detectCores()-1)
#########################################################
# between aperiodic and stable regimes
#########################################################
nrep=100 # number of sets
nset=20 # number of data in one set
ntotalset=4000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # power
source("functions.R")
# import persistence diagrams
load("./data_persistence_diagram.Rdata")
set.seed(75)
cl = makeCluster(detectCores()-1)
np=500 # number of permutation
#########################################################
# between aperiodic and stable regimes
#########################################################
nrep=100 # number of sets
nset=20 # number of data in one set
ntotalset=4000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # power
#########################################################
# between aperiodic regimes
#########################################################
nrep=100
nset=20
ntotalset=2000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # false positive rate
#########################################################
# between stable regimes
#########################################################
nrep=100
nset=20
ntotalset=2000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
PL.list1 = list()
PL.list2 = list()
for (ss in 1:nset){
PL.list1[[ss]]=PL.list[[(rr-1)*nset+ss+4000]]
PL.list2[[ss]]=PL.list[[(rr-1)*nset+ss+4000+ntotalset]]
}
PL.mat1 = landscape.matrix.from.list(PL.list1)
PL.mat2 = landscape.matrix.from.list(PL.list2)
pvals[rr]=permutation.test(PL.mat1,PL.mat2,num.repeats=np,cl)
}
sum(pvals<0.05)/nrep # false positive rate
stopCluster(cl)
source("functions.R")
# import persistence diagrams
load("./data_time_series.Rdata")
install.packages("dtw")
install.packages("dtw")
library(dtw)
set.seed(9)
dtw.group = function(ii,comb,ts){
dtw(ts[comb[ii,1],],ts[comb[ii,2],],distance.only = T)$distance
}
perm.test = function(ts){
comb = combinations(nrow(ts),2)
mean(apply(matrix(1:nrow(comb)),1,dtw.group,comb,ts))
}
dtw.perm.test = function(ts1,ts2,num.repeats){
basedtw = perm.test(ts1)+perm.test(ts2)
ts=rbind(ts1,ts2)
count = 0
for (i in 1:num.repeats){
permutation = sample(1:nrow(ts))
dtwd = perm.test(ts[permutation[1:nrow(ts1)],])+perm.test(ts[-permutation[1:nrow(ts1)],])
if (dtwd <= basedtw)
count <- count + 1
}
return(count/num.repeats)
}
testn=100
# between stable and aperiodic
nrep=100
nset=20
ntotalset=4000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
print(rr)
pvals[rr]=dtw.perm.test(Time_Series_Data[rr*(1:nset),],Time_Series_Data[rr*(1:nset)+ntotalset,],num.repeats=testn)
}
sum(pvals<0.05)/nrep
# between aperiodic
nrep=100
nset=20
ntotalset=2000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
print(rr)
pvals[rr]=dtw.perm.test(Time_Series_Data[rr*(1:nset),],Time_Series_Data[rr*(1:nset)+ntotalset,],num.repeats=testn)
}
sum(pvals<0.05)/nrep
# between stable
nrep=100
nset=20
ntotalset=2000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
print(rr)
pvals[rr]=dtw.perm.test(Time_Series_Data[4000+rr*(1:nset),],Time_Series_Data[4000+rr*(1:nset)+ntotalset,],num.repeats=testn)
}
sum(pvals<0.05)/nrep
library(gtools)
install.packages("gtools")
library(gtools)
set.seed(9)
dtw.group = function(ii,comb,ts){
dtw(ts[comb[ii,1],],ts[comb[ii,2],],distance.only = T)$distance
}
perm.test = function(ts){
comb = combinations(nrow(ts),2)
mean(apply(matrix(1:nrow(comb)),1,dtw.group,comb,ts))
}
dtw.perm.test = function(ts1,ts2,num.repeats){
basedtw = perm.test(ts1)+perm.test(ts2)
ts=rbind(ts1,ts2)
count = 0
for (i in 1:num.repeats){
permutation = sample(1:nrow(ts))
dtwd = perm.test(ts[permutation[1:nrow(ts1)],])+perm.test(ts[-permutation[1:nrow(ts1)],])
if (dtwd <= basedtw)
count <- count + 1
}
return(count/num.repeats)
}
testn=100
# between stable and aperiodic
nrep=100
nset=20
ntotalset=4000
pvals=rep(NA,nrep)
for (rr in 1:nrep){
print(rr)
pvals[rr]=dtw.perm.test(Time_Series_Data[rr*(1:nset),],Time_Series_Data[rr*(1:nset)+ntotalset,],num.repeats=testn)
}
sum(pvals<0.05)/nrep
